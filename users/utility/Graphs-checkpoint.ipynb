{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsData = pd.read_csv(\"C:/SHERYL MATHIAS/US Aug 2016/Fall 2017/INFM750/FinalDataSet.csv\" , encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_url</th>\n",
       "      <th>statuses/followers_count</th>\n",
       "      <th>friends/followers_count</th>\n",
       "      <th>user_has_url?</th>\n",
       "      <th>Final Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>90</td>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>itsabinakelley</td>\n",
       "      <td>Erica Kane</td>\n",
       "      <td>...</td>\n",
       "      <td>299</td>\n",
       "      <td>410</td>\n",
       "      <td>made in japan</td>\n",
       "      <td>3585</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.37</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SocialNewsDesk</td>\n",
       "      <td>132</td>\n",
       "      <td>1.881336e+07</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>...</td>\n",
       "      <td>13095</td>\n",
       "      <td>768</td>\n",
       "      <td>Wausau, Wisconsin</td>\n",
       "      <td>53691</td>\n",
       "      <td>True</td>\n",
       "      <td>http://t.co/Ooqm8p3JBi</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>03-11-2017 16:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>112</td>\n",
       "      <td>2.722783e+08</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>4261</td>\n",
       "      <td>3956</td>\n",
       "      <td>Houston, Texas, U.S.A.</td>\n",
       "      <td>48019</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/xZ5kENca0d</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "      <td>89</td>\n",
       "      <td>3.360066e+07</td>\n",
       "      <td>gdubb79</td>\n",
       "      <td>Gabriel Woofter</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5649</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/tJVLcw98YK</td>\n",
       "      <td>25.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>97</td>\n",
       "      <td>1.844070e+07</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>...</td>\n",
       "      <td>1146</td>\n",
       "      <td>5000</td>\n",
       "      <td>Texas</td>\n",
       "      <td>69033</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique ID                                               text  \\\n",
       "0          1  Hurricane Katrina - Saints go to the Superbowl...   \n",
       "1          2  Students from Riverview Elementary set a goal ...   \n",
       "2          3  Harvey caused more than $74M in damage to floo...   \n",
       "3          4  I added a video to a @YouTube playlist https:/...   \n",
       "4          5  DFW businesses accused of price gouging during...   \n",
       "\n",
       "         created_at  retweet_count  favorite_count              source  \\\n",
       "0  03-11-2017 17:28              0               1  Twitter for iPhone   \n",
       "1  03-11-2017 17:28              0               0      SocialNewsDesk   \n",
       "2  03-11-2017 16:37              0               0              Buffer   \n",
       "3  03-11-2017 17:27              0               0              Google   \n",
       "4  03-11-2017 17:27              0               0  Twitter Web Client   \n",
       "\n",
       "   length       user_id user_screen_name        user_name     ...       \\\n",
       "0      90  8.800000e+17   itsabinakelley       Erica Kane     ...        \n",
       "1     132  1.881336e+07             WAOW             WAOW     ...        \n",
       "2     112  2.722783e+08    HOUmanitarian    HOUmanitarian     ...        \n",
       "3      89  3.360066e+07          gdubb79  Gabriel Woofter     ...        \n",
       "4      97  1.844070e+07     TexasAmerica     TexasAmerica     ...        \n",
       "\n",
       "  user_followers_count user_friends_count           user_location  \\\n",
       "0                  299                410           made in japan   \n",
       "1                13095                768       Wausau, Wisconsin   \n",
       "2                 4261               3956  Houston, Texas, U.S.A.   \n",
       "3                  220                683                     NaN   \n",
       "4                 1146               5000                   Texas   \n",
       "\n",
       "   user_statuses_count user_verified                 user_url  \\\n",
       "0                 3585         False                      NaN   \n",
       "1                53691          True   http://t.co/Ooqm8p3JBi   \n",
       "2                48019         False  https://t.co/xZ5kENca0d   \n",
       "3                 5649         False  https://t.co/tJVLcw98YK   \n",
       "4                69033         False                      NaN   \n",
       "\n",
       "   statuses/followers_count friends/followers_count  user_has_url?  \\\n",
       "0                     11.99                    1.37             No   \n",
       "1                      4.10                    0.06            Yes   \n",
       "2                     11.27                    0.93            Yes   \n",
       "3                     25.68                    3.10            Yes   \n",
       "4                     60.24                    4.36             No   \n",
       "\n",
       "   Final Label  \n",
       "0         REAL  \n",
       "1         REAL  \n",
       "2         REAL  \n",
       "3         REAL  \n",
       "4         REAL  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly import graph_objs\n",
    "plotly.tools.set_credentials_file(username='swmathias', api_key='IUApAvbxLdKWUicRaovv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~swmathias/32.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = len(tweetsData[tweetsData[\"Final Label\"] == \"FAKE\"])\n",
    "real = len(tweetsData[tweetsData[\"Final Label\"] == \"REAL\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"fake\",\"real\"],\n",
    "        y=[fake, real],\n",
    ")]\n",
    "py.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Fake and Real Tweets distribution in training set\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    "\n",
    "def preproces(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetsData['tokenized_text']= tweetsData['text'].apply(preproces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHERYL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removes stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tweetsData['token_texts'] = tweetsData['tokenized_text'].apply(lambda x : [w for w in x if w.lower() not in stop_words])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_url</th>\n",
       "      <th>statuses/followers_count</th>\n",
       "      <th>friends/followers_count</th>\n",
       "      <th>user_has_url?</th>\n",
       "      <th>Final Label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>token_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>90</td>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>itsabinakelley</td>\n",
       "      <td>Erica Kane</td>\n",
       "      <td>...</td>\n",
       "      <td>made in japan</td>\n",
       "      <td>3585</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.37</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, to, the, S...</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, Superbowl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SocialNewsDesk</td>\n",
       "      <td>132</td>\n",
       "      <td>1.881336e+07</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>...</td>\n",
       "      <td>Wausau, Wisconsin</td>\n",
       "      <td>53691</td>\n",
       "      <td>True</td>\n",
       "      <td>http://t.co/Ooqm8p3JBi</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Students, from, Riverview, Elementary, set, a...</td>\n",
       "      <td>[Students, Riverview, Elementary, set, goal, $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>03-11-2017 16:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>112</td>\n",
       "      <td>2.722783e+08</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>Houston, Texas, U.S.A.</td>\n",
       "      <td>48019</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/xZ5kENca0d</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0.93</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[Harvey, caused, more, than, $, 74, M, in, dam...</td>\n",
       "      <td>[Harvey, caused, $, 74, damage, flood, control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "      <td>89</td>\n",
       "      <td>3.360066e+07</td>\n",
       "      <td>gdubb79</td>\n",
       "      <td>Gabriel Woofter</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5649</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/tJVLcw98YK</td>\n",
       "      <td>25.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[I, added, a, video, to, a, @YouTube, playlist...</td>\n",
       "      <td>[added, video, @YouTube, playlist, https://t.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>97</td>\n",
       "      <td>1.844070e+07</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>69033</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>No</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[DFW, businesses, accused, of, price, gouging,...</td>\n",
       "      <td>[DFW, businesses, accused, price, gouging, Hur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique ID                                               text  \\\n",
       "0          1  Hurricane Katrina - Saints go to the Superbowl...   \n",
       "1          2  Students from Riverview Elementary set a goal ...   \n",
       "2          3  Harvey caused more than $74M in damage to floo...   \n",
       "3          4  I added a video to a @YouTube playlist https:/...   \n",
       "4          5  DFW businesses accused of price gouging during...   \n",
       "\n",
       "         created_at  retweet_count  favorite_count              source  \\\n",
       "0  03-11-2017 17:28              0               1  Twitter for iPhone   \n",
       "1  03-11-2017 17:28              0               0      SocialNewsDesk   \n",
       "2  03-11-2017 16:37              0               0              Buffer   \n",
       "3  03-11-2017 17:27              0               0              Google   \n",
       "4  03-11-2017 17:27              0               0  Twitter Web Client   \n",
       "\n",
       "   length       user_id user_screen_name        user_name  \\\n",
       "0      90  8.800000e+17   itsabinakelley       Erica Kane   \n",
       "1     132  1.881336e+07             WAOW             WAOW   \n",
       "2     112  2.722783e+08    HOUmanitarian    HOUmanitarian   \n",
       "3      89  3.360066e+07          gdubb79  Gabriel Woofter   \n",
       "4      97  1.844070e+07     TexasAmerica     TexasAmerica   \n",
       "\n",
       "                         ...                                   user_location  \\\n",
       "0                        ...                                   made in japan   \n",
       "1                        ...                               Wausau, Wisconsin   \n",
       "2                        ...                          Houston, Texas, U.S.A.   \n",
       "3                        ...                                             NaN   \n",
       "4                        ...                                           Texas   \n",
       "\n",
       "  user_statuses_count  user_verified                 user_url  \\\n",
       "0                3585          False                      NaN   \n",
       "1               53691           True   http://t.co/Ooqm8p3JBi   \n",
       "2               48019          False  https://t.co/xZ5kENca0d   \n",
       "3                5649          False  https://t.co/tJVLcw98YK   \n",
       "4               69033          False                      NaN   \n",
       "\n",
       "  statuses/followers_count  friends/followers_count  user_has_url?  \\\n",
       "0                    11.99                     1.37             No   \n",
       "1                     4.10                     0.06            Yes   \n",
       "2                    11.27                     0.93            Yes   \n",
       "3                    25.68                     3.10            Yes   \n",
       "4                    60.24                     4.36             No   \n",
       "\n",
       "  Final Label                                     tokenized_text  \\\n",
       "0        REAL  [Hurricane, Katrina, -, Saints, go, to, the, S...   \n",
       "1        REAL  [Students, from, Riverview, Elementary, set, a...   \n",
       "2        REAL  [Harvey, caused, more, than, $, 74, M, in, dam...   \n",
       "3        REAL  [I, added, a, video, to, a, @YouTube, playlist...   \n",
       "4        REAL  [DFW, businesses, accused, of, price, gouging,...   \n",
       "\n",
       "                                         token_texts  \n",
       "0  [Hurricane, Katrina, -, Saints, go, Superbowl,...  \n",
       "1  [Students, Riverview, Elementary, set, goal, $...  \n",
       "2  [Harvey, caused, $, 74, damage, flood, control...  \n",
       "3  [added, video, @YouTube, playlist, https://t.c...  \n",
       "4  [DFW, businesses, accused, price, gouging, Hur...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #function defined to calculate number of occurences of a symbol\n",
    "def count_occurences(character, word_array):\n",
    "    counter = 0\n",
    "    for j, word in enumerate(word_array):\n",
    "        for char in word:\n",
    "            if char == character:\n",
    "                counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculates number of ?, !, hashtags and mentions\n",
    "tweetsData['no_of_question_marks'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"?\", txt)) \n",
    "tweetsData['no_of_exclamation_marks'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"!\", txt)) \n",
    "tweetsData['no_of_hashtags'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"#\", txt)) \n",
    "tweetsData['no_of_mentions'] = tweetsData['token_texts'].apply(lambda txt: count_occurences(\"@\", txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_by_regex(regex,plain_text):\n",
    "    return len(re.findall(regex,plain_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>token_texts</th>\n",
       "      <th>no_of_question_marks</th>\n",
       "      <th>no_of_exclamation_marks</th>\n",
       "      <th>no_of_hashtags</th>\n",
       "      <th>no_of_mentions</th>\n",
       "      <th>no_of_urls</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>no_of_colon_marks</th>\n",
       "      <th>no_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>90</td>\n",
       "      <td>8.800000e+17</td>\n",
       "      <td>itsabinakelley</td>\n",
       "      <td>Erica Kane</td>\n",
       "      <td>...</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, to, the, S...</td>\n",
       "      <td>[Hurricane, Katrina, -, Saints, go, Superbowl,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hurricane Katrina - Saints go to the Superbowl...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>03-11-2017 17:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SocialNewsDesk</td>\n",
       "      <td>132</td>\n",
       "      <td>1.881336e+07</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>WAOW</td>\n",
       "      <td>...</td>\n",
       "      <td>[Students, from, Riverview, Elementary, set, a...</td>\n",
       "      <td>[Students, Riverview, Elementary, set, goal, $...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Students from Riverview Elementary set a goal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>03-11-2017 16:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>112</td>\n",
       "      <td>2.722783e+08</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>HOUmanitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>[Harvey, caused, more, than, $, 74, M, in, dam...</td>\n",
       "      <td>[Harvey, caused, $, 74, damage, flood, control...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harvey caused more than $74M in damage to floo...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I added a video to a @YouTube playlist https:/...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "      <td>89</td>\n",
       "      <td>3.360066e+07</td>\n",
       "      <td>gdubb79</td>\n",
       "      <td>Gabriel Woofter</td>\n",
       "      <td>...</td>\n",
       "      <td>[I, added, a, video, to, a, @YouTube, playlist...</td>\n",
       "      <td>[added, video, @YouTube, playlist, https://t.c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I added a video to a  playlist Heroes of Hurri...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>03-11-2017 17:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>97</td>\n",
       "      <td>1.844070e+07</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>TexasAmerica</td>\n",
       "      <td>...</td>\n",
       "      <td>[DFW, businesses, accused, of, price, gouging,...</td>\n",
       "      <td>[DFW, businesses, accused, price, gouging, Hur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DFW businesses accused of price gouging during...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique ID                                               text  \\\n",
       "0          1  Hurricane Katrina - Saints go to the Superbowl...   \n",
       "1          2  Students from Riverview Elementary set a goal ...   \n",
       "2          3  Harvey caused more than $74M in damage to floo...   \n",
       "3          4  I added a video to a @YouTube playlist https:/...   \n",
       "4          5  DFW businesses accused of price gouging during...   \n",
       "\n",
       "         created_at  retweet_count  favorite_count              source  \\\n",
       "0  03-11-2017 17:28              0               1  Twitter for iPhone   \n",
       "1  03-11-2017 17:28              0               0      SocialNewsDesk   \n",
       "2  03-11-2017 16:37              0               0              Buffer   \n",
       "3  03-11-2017 17:27              0               0              Google   \n",
       "4  03-11-2017 17:27              0               0  Twitter Web Client   \n",
       "\n",
       "   length       user_id user_screen_name        user_name     ...       \\\n",
       "0      90  8.800000e+17   itsabinakelley       Erica Kane     ...        \n",
       "1     132  1.881336e+07             WAOW             WAOW     ...        \n",
       "2     112  2.722783e+08    HOUmanitarian    HOUmanitarian     ...        \n",
       "3      89  3.360066e+07          gdubb79  Gabriel Woofter     ...        \n",
       "4      97  1.844070e+07     TexasAmerica     TexasAmerica     ...        \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [Hurricane, Katrina, -, Saints, go, to, the, S...   \n",
       "1  [Students, from, Riverview, Elementary, set, a...   \n",
       "2  [Harvey, caused, more, than, $, 74, M, in, dam...   \n",
       "3  [I, added, a, video, to, a, @YouTube, playlist...   \n",
       "4  [DFW, businesses, accused, of, price, gouging,...   \n",
       "\n",
       "                                         token_texts  no_of_question_marks  \\\n",
       "0  [Hurricane, Katrina, -, Saints, go, Superbowl,...                     0   \n",
       "1  [Students, Riverview, Elementary, set, goal, $...                     0   \n",
       "2  [Harvey, caused, $, 74, damage, flood, control...                     0   \n",
       "3  [added, video, @YouTube, playlist, https://t.c...                     0   \n",
       "4  [DFW, businesses, accused, price, gouging, Hur...                     0   \n",
       "\n",
       "   no_of_exclamation_marks no_of_hashtags  no_of_mentions  no_of_urls  \\\n",
       "0                        0              0               0           0   \n",
       "1                        0              0               0           1   \n",
       "2                        0              0               1           1   \n",
       "3                        0              0               1           1   \n",
       "4                        0              0               0           1   \n",
       "\n",
       "                                        cleaned_text  no_of_colon_marks  \\\n",
       "0  Hurricane Katrina - Saints go to the Superbowl...                  0   \n",
       "1  Students from Riverview Elementary set a goal ...                  0   \n",
       "2  Harvey caused more than $74M in damage to floo...                  0   \n",
       "3  I added a video to a  playlist Heroes of Hurri...                  0   \n",
       "4  DFW businesses accused of price gouging during...                  0   \n",
       "\n",
       "   no_of_words  \n",
       "0           12  \n",
       "1           18  \n",
       "2           12  \n",
       "3           11  \n",
       "4           12  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculates number of URLs in a tweet\n",
    "tweetsData['no_of_urls'] = tweetsData['text'].apply(lambda txt:count_by_regex(\"http.?://[^\\s]+[\\s]?\",txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not working as of now. Need to look at it later if needed\n",
    "class EmoticonDetector:\n",
    "    emoticons = {}\n",
    "\n",
    "    def __init__(self, emoticon_file=\"C://SHERYL MATHIAS/US Aug 2016/Fall 2017/INFM750/emoticons.txt\"):\n",
    "        from pathlib import Path\n",
    "        content = Path(emoticon_file).read_text()\n",
    "        positive = True\n",
    "        for line in content.split(\"\\n\"):\n",
    "            if \"positive\" in line.lower():\n",
    "                positive = True\n",
    "                continue\n",
    "            elif \"negative\" in line.lower():\n",
    "                positive = False\n",
    "                continue\n",
    "\n",
    "            self.emoticons[line] = positive\n",
    "\n",
    "    def is_positive(self, emoticon):\n",
    "        if emoticon in self.emoticons:\n",
    "            return self.emoticons[emoticon]\n",
    "        return False\n",
    "\n",
    "    def is_emoticon(self, to_check):\n",
    "        return to_check in self.emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_by_lambda(expression, word_array):\n",
    "    return len(list(filter(expression, word_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#May need this code later. But this code does not work\n",
    "#ed = EmoticonDetector()\n",
    "#tweetsData['no_of_positive_emoticons'] = tweetsData['text'].apply(lambda txt: count_by_lambda(lambda word: ed.is_emoticon(word) and ed.is_positive(word), txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweetsData.to_csv(\"C://SHERYL MATHIAS/US Aug 2016/Fall 2017/INFM750/FinalDS_AdditionalFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tweetsData['no_of_uppercase_words'] = tweetsData['tokenized_text'].apply(lambda txt: count_by_lambda(lambda word: word == word.upper(), \n",
    "#                                                                                          txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to Remove URLs and mentions from tweets\n",
    "def remove_url_by_regex(pattern,string):\n",
    "    return re.sub(pattern,\"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removes URLs\n",
    "tweetsData['cleaned_text'] = tweetsData['text'].apply(lambda txt:remove_url_by_regex(\"http.?://[^\\s]+[\\s]?\",txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removes mentions\n",
    "tweetsData['cleaned_text'] = tweetsData['cleaned_text'].apply(lambda txt:remove_url_by_regex(r'(?:@[\\w_]+)',txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how much for the maple syrup??? $20.99? That's?ricidulous!!!\n",
      "how much for the maple syrup 2099 That'sricidulous\n"
     ]
    }
   ],
   "source": [
    "#strs = \"how much for the maple syrup??? $20.99? That's?ricidulous!!!\"\n",
    "# print(strs)\n",
    "# nstr = re.sub(r'[?|$|.|!]',r'',strs)\n",
    "# print (nstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculates number of colon marks\n",
    "tweetsData['no_of_colon_marks'] = tweetsData['cleaned_text'].apply(lambda txt: count_occurences(\":\", txt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove punctuation marks\n",
    "tweetsData['cleaned_text'] = tweetsData['cleaned_text'].apply(lambda txt:remove_url_by_regex(r'[,|:|\\|=|&|;|%|$|@|^|*|-|#|?|!|.]',txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counts number of words\n",
    "tweetsData['no_of_words'] = tweetsData['cleaned_text'].apply(lambda txt:len(re.findall(r'\\w+',txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
